# Task 1: Data Collection

Data collection can be carried out without any restriction on programming languages (python is only a warm suggestion) and/or online sources.
The use of already crawled network datasets available on the internet **will not** be considered as a valid option.

## Workflow

1. Identify an online data source,
2. Crawl data from it (or collect them through API if available),
3. Build up a network from the data!

## Requirement:
- The network must have **at least** 10-15k nodes. 
Specific cases involving the analysis of smaller networks must be discussed beforehand with the instructor.

- The produced code must be stored into the *code* folder: please, briefly comment the choices made/strategies adopted to perform the crawling.

- The final version of the data (i.e., the network and, if present, all additional data) must be compressed and stored into the **data** folder.

## Data Sources ideas:
Twitter, Last.fm, Blogs, Reddit, Blabla car, Linkedin, Corpora, Wikipedia, Newspaper...
