{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0_DataCollection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit ('base': conda)",
      "language": "python",
      "name": "python37464bitbaseconda7bde14bc76d04e6f9be1b82a66921208"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "luIibLphxlom"
      },
      "source": [
        "# Academic (Sub)Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fTkjY0Q_xlon"
      },
      "source": [
        "This notebook is aimed to collect **Worldwide Academic Coautorship** data, in order to represent and analyse them through a network structure. \n",
        "The selected data source is the Open Academic Graph provided by Microsoft at https://www.openacademic.ai/oag/: from such source we have downloaded both aminer_papers_\\*.zip and aminer_authors_\\*.zip sets of files, where \\* stands for the parts in which authors and papers info are splitted.\n",
        "\n",
        "The used modules are imported in the first line, while requirements.txt file includes the requirements for this notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8L7OhM4GhH_",
        "colab_type": "text"
      },
      "source": [
        "Only for Google Colab Research"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqDnil73GhIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b6c4f1ab-53a0-4872-8a95-f2563c00d4bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Mu32193xlon",
        "colab": {}
      },
      "source": [
        "from itertools import islice\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "from itertools import islice\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fzQwuVlUxloq"
      },
      "source": [
        "## Raw Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1yjMWB1Uxlor"
      },
      "source": [
        "The main challenge of the task is represented by the size of the files. As shown in the following lines we have to process:\n",
        "* About 35 GB of authors related information\n",
        "* About 138 GB of papers related information\n",
        "\n",
        "In this project, such files are respectively located in /data/authors and /data/papers folders.\n",
        "\n",
        "Due to obvious reasons and limitations we will only push some subsamples of them to the GitHub repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iG0xzDN0xlor",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a807ae6c-9bab-4656-b145-6df934c672b6"
      },
      "source": [
        "paperFiles = glob.glob('/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/*.txt')\n",
        "for filename in paperFiles:\n",
        "    print(filename + \"\\t\\t\" + str(os.path.getsize(filename)/100000000) + \" KB\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_0.txt\t\t100.00003049 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_1.txt\t\t100.00001184 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_2.txt\t\t100.00004163 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_3.txt\t\t100.00001016 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_4.txt\t\t100.00004774 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_5.txt\t\t100.00003508 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_6.txt\t\t100.00004818 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_7.txt\t\t100.00003416 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_8.txt\t\t100.00004111 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_9.txt\t\t100.00003411 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_10.txt\t\t100.00001843 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_11.txt\t\t100.00001845 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_12.txt\t\t100.00002003 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_13.txt\t\t100.00009657 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/papers/aminer_papers_14.txt\t\t90.10205432 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jA8Bx7Y8xlox",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "17b67abf-4621-45d3-abd2-62ac469a9634"
      },
      "source": [
        "authorFiles = glob.glob('/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/*.txt')\n",
        "for filename in authorFiles:\n",
        "    print(filename + \"\\t\\t\" + str(os.path.getsize(filename)/100000000) + \" KB\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_1.txt\t\t8.5413124 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_10.txt\t\t6.88733723 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_2.txt\t\t14.09760167 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_0.txt\t\t11.84497563 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_3.txt\t\t12.01266825 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_5.txt\t\t19.05002495 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_15.txt\t\t25.1091867 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_11.txt\t\t24.86744147 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_6.txt\t\t25.30414925 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_16.txt\t\t24.64037214 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_4.txt\t\t19.21970226 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_12.txt\t\t24.83161622 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_7.txt\t\t16.44248974 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_13.txt\t\t24.959896 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_8.txt\t\t12.16154144 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_17.txt\t\t20.51281684 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_18.txt\t\t19.05541594 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_19.txt\t\t18.26437946 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_9.txt\t\t25.5197759 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data/authors/aminer_authors_14.txt\t\t25.0915904 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YVBT-kSexloz"
      },
      "source": [
        "## The Graph\n",
        "\n",
        "After some explorations of data, that is documented in the report of this notebook, we have decided to fetch only authors whose collaborations occurred in **2016**. \n",
        "We collect authors' information in the following way:\n",
        "* Firstly, we iterate over all the available papers in order to fetch the authors of those papers whose field year is equal to 2016. We remark that this step has been performed in a streaming fashion, loading chunks of 10k items (i.e. papers): in this way we avoid memory overloading and the whole scan of 138 GB of data takes about half an hour. \n",
        "* Secondly, we store the newtwork components \"on the fly\", inserting the relevant objects into two lists:\n",
        "    * Authors (nodes): for the moment they are made up only of the authors' IDs.\n",
        "    * Collaborations (weighted links): made up of the number of collaboration between two nodes during the selected year\n",
        "\n",
        "Notice that **we postpone the creation of the graph**: the first goal is to generate the sets of nodes and links in order to store them as files. Later, we will have the freedom to use the best analytical tool depending on both our needs and the size of the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s4ooaGD4xloz"
      },
      "source": [
        "### Nodes and links\n",
        "In the following phase (i.e. retrieval of authors), the data structures representing nodes and links are:\n",
        "* A **dictionary** of strings (authors IDs) representing the nodes\n",
        "* A **dictionary of strings** representing pairs (author ID, author ID) which in turn represent the links\n",
        "\n",
        "This decision is motivated by the following observations:\n",
        "* Concertning the nodes, if we look at the following code chunks, in order to avoid duplication we need to check whether a node already exists before inserting it into the nodes *set*. This implies that we need to perform n lookups, where n is the size of the input (in our case about 6.3 millions): dictionaries are the best data structure in this case, since it provides both lookup and insertion in constant (i.e. optimal) time.\n",
        "* Using sets instead of double dictionaries would allows us to do not care about the double representation of the same undirected links: since the link (x, y) is the same as (y, x), we could perform the retrieving of its weight in constant time by using a dictionary who locates them in the same bucked (being them the same object!). Unfortunately, sets are not hashable object, hence we use one (or two) dictionary for each co-authorship. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vgns8Qgxxlo0",
        "colab": {}
      },
      "source": [
        "auth_dict = {}\n",
        "links_dict = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T-dkz2_zxlo2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "fe3de00f-96f8-4269-82fe-dcae13e3661d"
      },
      "source": [
        "chunk_size = 10000\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "for file in paperFiles: # For each aminer_papers_*.txt\n",
        "    with open(file, \"r\") as f:\n",
        "        while True:\n",
        "            chunk = list(islice(f, chunk_size)) # Loading chunk\n",
        "            if not chunk:\n",
        "                break\n",
        "            # Processing chunk\n",
        "            for paper in chunk: # Paper online processing\n",
        "                paper_info = json.loads(paper) \n",
        "                try:\n",
        "                    if(paper_info[\"year\"] == 2016):  # if year == 2016\n",
        "                        authors = paper_info[\"authors\"] # Fetch paper authors\n",
        "                        # Adding authors if absent\n",
        "                        for author in authors:\n",
        "                            try:\n",
        "                                a = auth_dict[author[\"id\"]] # test\n",
        "                            except:\n",
        "                                auth_dict[author[\"id\"]] = {}\n",
        "                        \n",
        "                        n = len(authors)\n",
        "                        if(n > 1):\n",
        "                            # Updating links among nodes\n",
        "                            for i in range(n):\n",
        "                                for j in range(i+1, n):\n",
        "                                    edge = ','.join(sorted([authors[i][\"id\"], authors[j][\"id\"]]))\n",
        "                                    try: # Incrementing egde weight by 1 (co-authorship)\n",
        "                                        links_dict[edge] = links_dict[edge] + 1\n",
        "                                    except: # Creating edge\n",
        "                                        links_dict[edge] = 1\n",
        "                    else: # year != 2016\n",
        "                        pass\n",
        "                except:\n",
        "                    pass # No year\n",
        "\n",
        "end = datetime.now()\n",
        "end-start"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.timedelta(seconds=2325, microseconds=158013)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0xFEZDJBxlo4"
      },
      "source": [
        "Number of nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a5uBsDupxlo5",
        "colab": {},
        "outputId": "a8f13e1d-22ab-44f0-b3ca-0708428b8630"
      },
      "source": [
        "nr_links = len(links_dict.keys())\n",
        "nr_links"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4511734"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IqZPGVyHxlo8"
      },
      "source": [
        "Number of links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zkwWJ2GVxlo8",
        "colab": {},
        "outputId": "4a22c27d-084a-465c-f5d4-8ca3fec37294"
      },
      "source": [
        "nr_authors = len(auth_dict.keys())\n",
        "nr_authors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "373263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bODt2uUmxlo-"
      },
      "source": [
        "Nodes avergage degree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "088xGznJxlo_",
        "colab": {},
        "outputId": "600f80b0-0954-488b-9841-0d5a9410e236"
      },
      "source": [
        "nr_links/nr_authors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.08727894272939"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JwLhse_1xlpB"
      },
      "source": [
        "## Writing nodes and links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pannlDMmxlpK",
        "colab": {}
      },
      "source": [
        "def save_obj(obj, name):\n",
        "    with open('data/obj/'+ name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNjilSzTGhId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_obj(auth_dict, \"authors\")\n",
        "save_obj(links_dict, \"links\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXnIT2RVGhIf",
        "colab_type": "text"
      },
      "source": [
        "## Reading nodes and links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-MjEXbRGhIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_obj(name):\n",
        "    with open('data/obj/' + name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_UwbCWIGhIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "read_auth = load_obj(\"authors\")\n",
        "read_links = load_obj(\"links\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2uc81igGhIj",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AEAAMpeGhIj",
        "colab_type": "code",
        "colab": {},
        "outputId": "d8181761-03f2-4025-b17b-d6358e80dc2b"
      },
      "source": [
        "read_links[list(read_links.keys())[1234567]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}