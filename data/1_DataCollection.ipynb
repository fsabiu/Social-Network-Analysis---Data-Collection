{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_DataCollection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit ('base': conda)",
      "language": "python",
      "name": "python37464bitbaseconda7bde14bc76d04e6f9be1b82a66921208"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "luIibLphxlom"
      },
      "source": [
        "# Academic (Sub)Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fTkjY0Q_xlon"
      },
      "source": [
        "This notebook is aimed to enrich data collected in the step 0. \n",
        "Here, author's data will be read in a streaming fashion, and relevant authors' information will be inserted in our authors data structure.\n",
        "\n",
        "In particular, for each author:\n",
        "* We read its ID\n",
        "  * If ID belongs to our authors IDs we save the following data:\n",
        "    * name\n",
        "    * h-index\n",
        "    * number of pubblications\n",
        "    * number of citations\n",
        "    * list of organizations\n",
        "    * fields of research\n",
        "  * Else we do nothing and such entry won't be stored in main mamory because of the online algorithm.\n",
        "\n",
        "After that, we will have all the information that we need in order to:\n",
        "* Discuss a cut-off in order to reduce the size of the graph\n",
        "* Chose the library with which we will implement the graph\n",
        "* Create the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn-t30MGXkJn",
        "colab_type": "text"
      },
      "source": [
        "Only for Google Colab Research"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPoZwW6BY5oh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2409826d-c6a1-4968-ef47-ac634a416c56"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Mu32193xlon",
        "colab": {}
      },
      "source": [
        "from itertools import islice\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "from itertools import islice\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fzQwuVlUxloq"
      },
      "source": [
        "## Reading authors data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1yjMWB1Uxlor"
      },
      "source": [
        "In the next chunk we show all the files containing information about the authors. We don't need all the entries of such file, but we do need to scan them once in order to fetch information related to the selected authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iG0xzDN0xlor",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "206360b6-787c-4f5f-9872-63bf536a7ac5"
      },
      "source": [
        "paperFiles = glob.glob('/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/*.txt')\n",
        "for filename in paperFiles:\n",
        "    print(filename + \"\\t\\t\" + str(os.path.getsize(filename)/100000000) + \" KB\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_1.txt\t\t8.5413124 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_10.txt\t\t6.88733723 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_2.txt\t\t14.09760167 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_0.txt\t\t11.84497563 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_3.txt\t\t12.01266825 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_5.txt\t\t19.05002495 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_15.txt\t\t25.1091867 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_11.txt\t\t24.86744147 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_6.txt\t\t25.30414925 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_16.txt\t\t24.64037214 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_4.txt\t\t19.21970226 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_12.txt\t\t24.83161622 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_7.txt\t\t16.44248974 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_13.txt\t\t24.959896 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_8.txt\t\t12.16154144 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_17.txt\t\t20.51281684 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_18.txt\t\t19.05541594 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_19.txt\t\t18.26437946 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_9.txt\t\t25.5197759 KB\n",
            "/content/drive/My Drive/NetworkScience/AcademicGraph/data-collection-2020_sabiu/data/authors/aminer_authors_14.txt\t\t25.0915904 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YVBT-kSexloz"
      },
      "source": [
        "## Information retrieval\n",
        "In the next chunks we read data in a streaming fashion. Once again the chunk size is 10k entries.\n",
        "\n",
        "One observation is in order at this point: we have to retrieve information related to m over n total authors, with n >> m. <br />\n",
        "In a usual batch algorithm we would implement this task by performing m lookups in the n entries (both sets are unsorted). Here, because of the online paradigm, we have to revert such approach: for each author whose information is stored, we look whether it is contained in dictionary. If yes, its information is fetched. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s4ooaGD4xloz"
      },
      "source": [
        "Reading stored data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tRlDHKxZhK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_obj(name):\n",
        "    with open('/content/drive/My Drive/NetworkScience/AcademicGraph/data/obj/' + name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vgns8Qgxxlo0",
        "colab": {}
      },
      "source": [
        "auth_dict = load_obj(\"authors\")\n",
        "links_dict = load_obj(\"links\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nasl6QCEsRR8",
        "colab_type": "text"
      },
      "source": [
        "### Scanning all authors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T-dkz2_zxlo2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71a1bcbb-9521-4d80-ee80-444f0012cf95"
      },
      "source": [
        "chunk_size = 10000\n",
        "count = 0\n",
        "start = datetime.now()\n",
        "\n",
        "for file in paperFiles: # For each aminer_papers_*.txt\n",
        "    with open(file, \"r\") as f:\n",
        "        while True:\n",
        "            chunk = list(islice(f, chunk_size)) # Loading chunk\n",
        "            if not chunk:\n",
        "                break\n",
        "            # Processing chunk\n",
        "            for paper in chunk: # Paper online processing\n",
        "                auth_info = json.loads(paper)\n",
        "                \n",
        "                auth_id = auth_info[\"id\"]\n",
        "                if(auth_id in auth_dict):\n",
        "                    auth_name = auth_info.get(\"name\")\n",
        "                    auth_orgs = auth_info.get(\"orgs\")\n",
        "                    auth_h_index = auth_info.get(\"h_index\")\n",
        "                    auth_n_pubs = auth_info.get(\"n_pubs\")\n",
        "                    auth_n_citation = auth_info.get(\"n_citation\")\n",
        "                    tags = auth_info.get(\"tags\")\n",
        "\n",
        "                    info = {}\n",
        "                    if(auth_name != None):\n",
        "                      info[\"name\"] = auth_name\n",
        "                    if(auth_orgs != None):\n",
        "                      info[\"orgs\"] = auth_orgs\n",
        "                    if(auth_h_index != None):\n",
        "                      info[\"h_index\"] = auth_h_index\n",
        "                    if(auth_n_pubs != None):\n",
        "                      info[\"n_pubs\"] = auth_n_pubs\n",
        "                    if(auth_n_citation != None):\n",
        "                      info[\"n_citation\"] = auth_n_citation\n",
        "                    if(tags != None):\n",
        "                      info[\"tags\"] = tags\n",
        "\n",
        "                    auth_dict[auth_id] = info\n",
        "end = datetime.now()\n",
        "end-start"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.timedelta(0, 979, 820776)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lDsiSOQqoLc",
        "colab_type": "text"
      },
      "source": [
        "### Checking new features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irY7eswcqn1e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30a07b6-26d1-42b1-f99e-b0bb60b13592"
      },
      "source": [
        "auth_dict[list(auth_dict.keys())[74557]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'h_index': 1,\n",
              " 'n_citation': 1,\n",
              " 'n_pubs': 8,\n",
              " 'name': 'Ron N. Alkalay',\n",
              " 'orgs': ['Beth Israel Deaconess Medical Center Orthopaedic Biomechanics Laboratory, Harvard Medical School, Boston, MA, USA'],\n",
              " 'tags': [{'t': 'Spinal Fusion', 'w': 1},\n",
              "  {'t': 'Bone Graft Substitute', 'w': 1},\n",
              "  {'t': 'Animal Model', 'w': 1},\n",
              "  {'t': 'Biomechanical Tests', 'w': 1}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JwLhse_1xlpB"
      },
      "source": [
        "### Writing updated nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pannlDMmxlpK",
        "colab": {}
      },
      "source": [
        "def save_obj(obj, name):\n",
        "    with open('/content/drive/My Drive/NetworkScience/AcademicGraph/data/obj/'+ name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn8GX4XLXkKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_obj(auth_dict, \"authors\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfH54RI5XkKF",
        "colab_type": "text"
      },
      "source": [
        "## Cutting off\n",
        "As shown in the next chunks, we have more than 373k authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVG5yju3XkKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth_dict = load_obj(\"authors\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCpXrfSVXkKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(auth_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEWMW7GCJre0",
        "colab_type": "text"
      },
      "source": [
        "### Exploring authors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd9RD7owXkKK",
        "colab_type": "text"
      },
      "source": [
        "How many authors with the following features?\n",
        "* Having more than 5 publications\n",
        "* Having at least one associated organization\n",
        "* Having more than 5 publications and with not null organization field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80nBpHfQXkKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "more_than5 = 0\n",
        "having_org = 0\n",
        "both = 0\n",
        "\n",
        "for auth in list(auth_dict.keys()):\n",
        "  auth_n_pubs = auth_dict[auth].get(\"n_pubs\")\n",
        "  orgs = auth_dict[auth].get(\"orgs\")\n",
        "  \n",
        "  # More than 5 publications\n",
        "  if(auth_n_pubs != None and auth_n_pubs > 5):\n",
        "    more_than5 = more_than5 + 1\n",
        "  \n",
        "  # Having organization field\n",
        "  if(orgs != None):\n",
        "    having_org += 1\n",
        "\n",
        "  # Having organization field and more than 5 publications\n",
        "  if(auth_n_pubs != None and auth_n_pubs > 5 and orgs != None):\n",
        "    both = both + 1\n",
        "\n",
        "print(more_than5)\n",
        "print(having_org)\n",
        "print(both)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1BeTdbA0yd-",
        "colab_type": "text"
      },
      "source": [
        "Let's store a filtered dictionary whose authors have an organization name and at least 5 publications (including all years up to 2016). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njp6X-33ztHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_authors = {}\n",
        "\n",
        "for auth in list(auth_dict.keys()):\n",
        "  auth_n_pubs = auth_dict[auth].get(\"n_pubs\")\n",
        "  orgs = auth_dict[auth].get(\"orgs\")\n",
        "\n",
        "  # Having organization field and more than 5 publications\n",
        "  if(auth_n_pubs != None and auth_n_pubs > 5 and orgs != None):\n",
        "    filtered_authors[auth] = auth_dict[auth]\n",
        "\n",
        "len(filtered_authors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgXIE47A3VYO",
        "colab_type": "text"
      },
      "source": [
        "Writing authors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0eNcQgn3RzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_obj(filtered_authors, \"filtered_authors\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up4ROK-EJwZG",
        "colab_type": "text"
      },
      "source": [
        "### Cutting links\n",
        "We could also filter depending on the number of links that involve each author. \n",
        "\n",
        "But first we create the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkB4EI1bPPgr",
        "colab_type": "text"
      },
      "source": [
        "## Creating the graph\n",
        "In this section we are going to use the original version of the authors dictionary. <br />\n",
        "It is made up of:\n",
        "* 373263 nodes\n",
        "* 4511734 links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcTWny3kJxez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_obj(name):\n",
        "    with open('/content/drive/My Drive/NetworkScience/AcademicGraph/data/obj/' + name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "#auth_dict = load_obj(\"filtered_authors\")\n",
        "auth_dict = load_obj(\"authors\")\n",
        "links_dict = load_obj(\"links\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIzgu7EwhI76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(''.join([str(len(auth_dict.keys())), \" nodes\"]))\n",
        "print(''.join([str(len(links_dict.keys())), \" links\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BksTQsQZ2Pd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install python-igraph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx9x4JOW2mSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import igraph\n",
        "from igraph import *\n",
        "import time\n",
        "print(igraph.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "020dGzSs23L_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = Graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUwa1F0g2_ZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g.add_vertices(list(auth_dict.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnJlJSlR6D_W",
        "colab_type": "text"
      },
      "source": [
        "Filtering links: obtaining only those related to actual nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioCY8mMk6EYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "links = []\n",
        "weights = []\n",
        "addToLinks = links.append\n",
        "addToWeights = weights.append\n",
        "\n",
        "for l in links_dict.keys():\n",
        "  nodes = l.split(',')\n",
        "  v1 = nodes[0]\n",
        "  v2 = nodes[1]\n",
        "  w = links_dict[l]\n",
        "\n",
        "  if(v1 in auth_dict and v2 in auth_dict):\n",
        "    addToLinks((v1, v2))\n",
        "    addToWeights(w)\n",
        "\n",
        "print(links[:3])\n",
        "print(weights[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZsvhUm8D7pm",
        "colab_type": "text"
      },
      "source": [
        "Adding links to the graph with their weight. <br />\n",
        "Attributes can be arbitrary Python objects, but if you are saving graphs to a file, only string and numeric attributes will be kept."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA3_kfkjhziT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(''.join([str(len(links)), \" remaining links\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFMuLGU4CbJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g.add_edges(links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBnIxP_dFcZs",
        "colab_type": "text"
      },
      "source": [
        "Adding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXNWRjK45r_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g.es[\"weight\"] = weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R6NETlbF07-",
        "colab_type": "text"
      },
      "source": [
        "Adding nodes attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulq3XJcw50du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing attribute lists\n",
        "ids = []\n",
        "names = []\n",
        "hindeces = []\n",
        "npubs = []\n",
        "ncits = []\n",
        "orgs = []\n",
        "tags = []\n",
        "\n",
        "# Filling attribute lists\n",
        "for a in auth_dict.keys():\n",
        "  # Appending id\n",
        "  ids.append(a)  \n",
        "  # Features\n",
        "  f = auth_dict[a]\n",
        "\n",
        "  if(\"name\" in f):\n",
        "    names.append(f[\"name\"])\n",
        "  else:\n",
        "    names.append(\"\")\n",
        "\n",
        "  if(\"h_index\" in f):\n",
        "    hindeces.append(f[\"h_index\"])\n",
        "  else:\n",
        "    hindeces.append(\"\")\n",
        "\n",
        "  if(\"n_pubs\" in f):\n",
        "    npubs.append(f[\"n_pubs\"])\n",
        "  else:\n",
        "    npubs.append(\"\")\n",
        "\n",
        "  if(\"n_citation\" in f):\n",
        "    ncits.append(f[\"n_citation\"])\n",
        "  else:\n",
        "    ncits.append(\"\")\n",
        "\n",
        "  if(\"orgs\" in f):\n",
        "    orgs.append(f[\"orgs\"])\n",
        "  else:\n",
        "    orgs.append(\"\")\n",
        "\n",
        "  if(\"tags.t\" in f):\n",
        "    tags.append(f[\"tags.t\"])\n",
        "  else:\n",
        "    tags.append(\"\")\n",
        "\n",
        "# Updating attribute lists\n",
        "g.vs[\"id\"] = id\n",
        "g.vs[\"name\"] = names\n",
        "g.vs[\"h_index\"] = hindeces\n",
        "g.vs[\"n_pubs\"] = npubs\n",
        "g.vs[\"n_citation\"] = ncits\n",
        "g.vs[\"orgs\"] = orgs\n",
        "g.vs[\"tags.t\"] = tags\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wBKFLSGM4Xc",
        "colab_type": "text"
      },
      "source": [
        "Storing graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTxh2MiJM42q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_obj(g, \"graph\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Q1MJr_KWOq",
        "colab_type": "text"
      },
      "source": [
        "### Degree distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa9jr1_6KY3j",
        "colab_type": "text"
      },
      "source": [
        "Maximum degree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTW3XlMX7hTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "degrees = g.degree()\n",
        "max_degree = max(degrees)\n",
        "max_degree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R6RAOAvK_SV",
        "colab_type": "text"
      },
      "source": [
        "x asses: degree (k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd8dLmDvImEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = list(range(max_degree + 1)) # k = [0, ..., 5134] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym1YTeRKLCxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = [degrees.count(i) for i in k]\n",
        "tot = sum(p)\n",
        "p = [i/tot for i in p]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1kF2J3dM3cO",
        "colab_type": "text"
      },
      "source": [
        "Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFwNVdS1MPFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter(x=k, y=p)\n",
        "fig.update_layout(xaxis_type=\"log\", yaxis_type=\"log\", width=800, height=600)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbitc9TVG1XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}